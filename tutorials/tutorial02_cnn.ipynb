{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U9M6mtQU1LE3"
   },
   "source": [
    "Lecture 2 (practice)\n",
    "======================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the assignment, you will gain hands-on experience working with Convolutional Neural Networks (CNNs).\n",
    "\n",
    "* **Custom CNN Model**:\n",
    "\n",
    "    Design and implement a custom CNN architecture tailored for the CIFAR-10, DTD, and COCO-O datasets. Train your model and evaluate its performance on each dataset. Consider discussing the design choices you made, such as the number of layers, types of layers, activation functions, etc., and how they contribute to your model's performance.\n",
    "\n",
    "* **Linear Probe of ResNet**:\n",
    "\n",
    "    Conduct a linear probe using the pre-trained ResNet features on the CIFAR-10, DTD, and COCO-O datasets. Analyze the effectiveness of transfer learning in speeding up training and improving accuracy. You may also want to compare this approach to training a model from scratch.\n",
    "\n",
    "* **Fine-tuning ResNet model**:\n",
    "\n",
    "    Fine-tune the ResNet model on the CIFAR-10, DTD, and COCO-O datasets to achieve better performance compared to the linear probe method. Discuss how fine-tuning impacts model accuracy and convergence speed. It's also worth exploring the balance between maintaining pre-trained knowledge and adapting to new tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "* The <b><font color=\"red\">red</font></b> color indicates the task that should be done, like <b><font color=\"red\">[TODO]</font></b>: ...\n",
    "* Addicitional comments, hints are in <b><font color=\"blue\">blue</font></b>. For example <b><font color=\"blue\">[HINT]</font></b>: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelimiaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install fiftyone\n",
    "# !pip install scikit-learn\n",
    "# !pip install tensorboard jupyter-tensorboard\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datasets import load_dataset # HuggingFace dedicated lib\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import fiftyone as fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# make plots a bit nicer\n",
    "plt.matplotlib.rcParams.update({'font.size': 18, 'font.family': 'serif'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(\n",
    "    model: nn.Module,    \n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader: torch.utils.data.DataLoader,\n",
    "    num_epoch: int,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    max_iter: int | None = None,     \n",
    "    writer: SummaryWriter | None = None\n",
    ") -> nn.Module:\n",
    "    \"\"\"Simple training script.\"\"\"    \n",
    "    \n",
    "    # Model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Log interval\n",
    "    log_interval = max(1, int(len(train_loader) / 100))\n",
    "    log_counter = 0\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        # Training part\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_amount = 0\n",
    "        for batch_idx, (inputs, labels) in tqdm(enumerate(train_loader), 'training', total=len(train_loader)):\n",
    "            \n",
    "            # Move the inputs and labels to the device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss and accuracy\n",
    "            _, preds = torch.max(output, 1)\n",
    "            running_amount += inputs.size(0)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "            # Log to tensorboard\n",
    "            if writer and batch_idx % log_interval == 0:\n",
    "                running_accuracy = (running_correct.float() / running_amount).item()\n",
    "                writer.add_scalar('Train/Loss', running_loss / running_amount, log_counter)\n",
    "                writer.add_scalar('Train/Accuracy', running_accuracy, log_counter)\n",
    "                log_counter += 1\n",
    "\n",
    "            if max_iter and batch_idx > max_iter:\n",
    "                break\n",
    "                    \n",
    "        # The train loss and accuracy\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_acc = running_correct.float() / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluation part\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, 'evaluation', total=len(val_loader)):\n",
    "                \n",
    "                # Move the inputs and labels to the device\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Update the running loss and accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Calculate the validation loss and accuracy\n",
    "        val_loss = running_loss / len(val_loader.dataset)\n",
    "        val_acc = running_correct.float() / len(val_loader.dataset)\n",
    "\n",
    "        # Best model\n",
    "        if val_acc > best_val_accuracy:\n",
    "            best_model_state = deepcopy(model.state_dict())\n",
    "            best_val_accuracy = val_acc\n",
    "\n",
    "        # Print the epoch results\n",
    "        print(\n",
    "            f'Epoch [{epoch + 1}/{num_epoch}], '\n",
    "            f'train loss: {train_loss:.4f}, train acc: {train_acc:.4f}, '\n",
    "            f'val loss: {val_loss:.4f}, val acc: {val_acc:.4f}'\n",
    "        )\n",
    "        # Log to tensorboard\n",
    "        if writer:\n",
    "            writer.add_scalar('TrainEpoch/Loss', train_loss, epoch + 1)\n",
    "            writer.add_scalar('TrainEpoch/Accuracy', train_acc, epoch + 1)            \n",
    "            writer.add_scalar('ValidationEpoch/Loss', val_loss, epoch + 1)\n",
    "            writer.add_scalar('ValidationEpoch/Accuracy', val_acc, epoch + 1)\n",
    "    \n",
    "    # Load the best model state before returning\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model: nn.Module,    \n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    ") -> np.ndarray:\n",
    "    \"\"\" Predict on a given dataloader. \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictations = []\n",
    "    ground_truth_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictations.extend(preds.cpu().numpy())\n",
    "            ground_truth_labels.extend(labels)\n",
    "    return np.array(predictations), np.array(ground_truth_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, n_classes: int):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTDdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = item['image']\n",
    "        label = item['label']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cifar = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_imagenet = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the local folder with the data\n",
    "path_data = \"./data\"\n",
    "os.makedirs(path_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load cifar10 dataset\n",
    "cifar10_dataset_train = torchvision.datasets.CIFAR10(root=path_data, train=True, download=True, transform=None)\n",
    "cifar10_dataset_test = torchvision.datasets.CIFAR10(root=path_data, train=False, download=True, transform=None)\n",
    "cifar10_classes_list = cifar10_dataset_train.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DTD dataset\n",
    "dtd_dataset = load_dataset(\"tanganke/dtd\", cache_dir=path_data)\n",
    "dtd_classes_list = dtd_dataset['train'].features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare COCO-O dataset\n",
    "if not os.path.exists(os.path.join(path_data, 'ood_coco')):\n",
    "    url = 'https://drive.google.com/uc?id=1aBfIJN0zo_i80Hv4p7Ch7M8pRzO37qbq'\n",
    "    zip_file_path = os.path.join(path_data, 'ood_coco.zip')\n",
    "    gdown.download(url, zip_file_path, quiet=False)\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path_data)\n",
    "cocoo_classes_list = os.listdir(os.path.join(path_data, 'ood_coco'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is completely optional. If you find it valuable, you may use TensorBoard or other similar tools to track the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for logs\n",
    "current_time = str(datetime.datetime.now().timestamp())\n",
    "path_log = 'logs/tensorboard/' + current_time\n",
    "\n",
    "# Set-up writer\n",
    "writer = SummaryWriter(path_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use 'crossentropy' for all classification problems\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "num_epoch = 3\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataloaders\n",
    "trainset = torchvision.datasets.CIFAR10(root=path_data, train=True, transform=transform_cifar)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root=path_data, train=False, transform=transform_cifar)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563\n",
      "313\n",
      "torch.Size([32, 3, 32, 32]) <class 'torch.Tensor'>\n",
      "torch.Size([32]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at the sizes of the loaders\n",
    "print(len(trainloader))\n",
    "print(len(testloader))\n",
    "\n",
    "# Let's check sizes of the batch and their types\n",
    "images, labels = next(iter(testloader))\n",
    "print(images.shape, type(images))\n",
    "print(labels.shape, type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up model and optimizer\n",
    "model_cifar = SimpleNet(n_classes=10)\n",
    "optimizer = torch.optim.SGD(model_cifar.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1563/1563 [00:09<00:00, 168.20it/s]\n",
      "evaluation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 252.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], train loss: 0.9430, train acc: 0.6709, val loss: 1.2537, val acc: 0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1563/1563 [00:09<00:00, 167.24it/s]\n",
      "evaluation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 255.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], train loss: 0.9467, train acc: 0.6721, val loss: 1.2861, val acc: 0.5771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1563/1563 [00:09<00:00, 168.88it/s]\n",
      "evaluation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 254.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], train loss: 0.9153, train acc: 0.6816, val loss: 1.3155, val acc: 0.5858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1563/1563 [00:09<00:00, 169.63it/s]\n",
      "evaluation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 250.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], train loss: 0.9139, train acc: 0.6799, val loss: 1.2882, val acc: 0.5770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1563/1563 [00:09<00:00, 168.45it/s]\n",
      "evaluation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 255.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], train loss: 0.9064, train acc: 0.6868, val loss: 1.2758, val acc: 0.5983\n",
      "CPU times: user 52.1 s, sys: 6 s, total: 58.1 s\n",
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = train_and_validate(\n",
    "    model=model_cifar, \n",
    "    train_loader=trainloader, \n",
    "    val_loader=testloader, \n",
    "    num_epoch=num_epoch, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    device=device, \n",
    "    writer=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictations\n",
    "predictations, true_labels = predict(model=best_model, data_loader=testloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.58      0.66      0.62      1000\n",
      "  automobile       0.76      0.74      0.75      1000\n",
      "        bird       0.48      0.52      0.50      1000\n",
      "         cat       0.36      0.52      0.43      1000\n",
      "        deer       0.54      0.51      0.52      1000\n",
      "         dog       0.55      0.44      0.49      1000\n",
      "        frog       0.76      0.64      0.69      1000\n",
      "       horse       0.73      0.56      0.63      1000\n",
      "        ship       0.66      0.75      0.70      1000\n",
      "       truck       0.75      0.63      0.68      1000\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.62      0.60      0.60     10000\n",
      "weighted avg       0.62      0.60      0.60     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed analysis (report)\n",
    "print(classification_report(true_labels, predictations, target_names=cifar10_classes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[661,  31,  49,  26,  25,  18,   7,  15, 137,  31],\n",
       "       [ 47, 736,   7,  22,  11,   3,   6,  10,  94,  64],\n",
       "       [ 99,   7, 523, 112,  93,  49,  44,  26,  31,  16],\n",
       "       [ 40,  10,  82, 524,  67, 144,  58,  31,  22,  22],\n",
       "       [ 37,   6, 143, 125, 512,  40,  53,  64,  14,   6],\n",
       "       [ 27,   5,  90, 306,  63, 442,  10,  35,   7,  15],\n",
       "       [ 15,   7,  80, 159,  62,  16, 640,   4,   6,  11],\n",
       "       [ 31,  10,  83,  89, 101,  88,  12, 561,   7,  18],\n",
       "       [114,  25,  13,  41,  11,   5,   5,   2, 751,  33],\n",
       "       [ 65, 132,  21,  40,  10,   5,   9,  21,  64, 633]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detailed analysis (confusion matrix)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictations)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cifar10_classes_list)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp.plot(cmap='Blues', ax=ax, xticks_rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "num_epoch = 5\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataloaders\n",
    "trainset = DTDdataset(dtd_dataset['train'], transform=transform_cifar)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testset = DTDdataset(dtd_dataset['test'], transform=transform_cifar)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\">[TODO]</font></b>: Following the example of 'cifar10' dataset complete the training from scratch for DTD dataset from this point.\n",
    "\n",
    "What is the accuracy? Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "num_epoch = 5\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\">[TODO]</font></b>: Following the example of 'cifar10' dataset complete the training from scratch for COCO-O dataset from this point.\n",
    "\n",
    "<b><font color=\"blue\">[HINT]</font></b>: You will need to write the custom class for the dataloader similar to 'DTDdataset'.\n",
    "\n",
    "What is the accuracy? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, resnet50\n",
    "from torchvision.models import ResNet18_Weights, ResNet50_Weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "num_epoch = 3\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataloaders\n",
    "# Note that we've changed the 'transform'\n",
    "trainset = torchvision.datasets.CIFAR10(root=path_data, train=True, transform=transform_imagenet)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root=path_data, train=False, transform=transform_imagenet)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "model_cifar = resnet18(weights=ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: We will first train only the last layer, freezing the rest of parameters.\n",
    "# This can be considered as a getting 'resnet' features and making linear probe on top of this.\n",
    "for param in model_cifar.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the very last layer\n",
    "num_classes = len(cifar10_classes_list)\n",
    "model_cifar.fc = torch.nn.Linear(model_cifar.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up optimizer\n",
    "optimizer = torch.optim.SGD(model_cifar.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   6%|██████████▊                                                                                                                                                             | 101/1563 [00:06<01:37, 15.03it/s]\n",
      "evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:19<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], train loss: 0.0850, train acc: 0.0353, val loss: 0.8752, val acc: 0.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   6%|██████████▊                                                                                                                                                             | 101/1563 [00:06<01:36, 15.12it/s]\n",
      "evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:19<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], train loss: 0.0655, train acc: 0.0435, val loss: 0.8812, val acc: 0.6992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   6%|██████████▊                                                                                                                                                             | 101/1563 [00:06<01:36, 15.22it/s]\n",
      "evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:19<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], train loss: 0.0640, train acc: 0.0444, val loss: 0.9309, val acc: 0.6952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   6%|██████████▊                                                                                                                                                             | 101/1563 [00:06<01:36, 15.17it/s]\n",
      "evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:19<00:00, 16.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], train loss: 0.0603, train acc: 0.0455, val loss: 0.8746, val acc: 0.7181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   6%|██████████▊                                                                                                                                                             | 101/1563 [00:06<01:37, 15.07it/s]\n",
      "evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:19<00:00, 16.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], train loss: 0.0589, train acc: 0.0456, val loss: 0.7219, val acc: 0.7610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# We repeat the same training process as before.\n",
    "# Note: To expedite the process, the parameter max_iter is set to 100. Consider increasing this value if you want to achieve better results.\n",
    "best_model = train_and_validate(\n",
    "    model=model_cifar, \n",
    "    train_loader=trainloader, \n",
    "    val_loader=testloader, \n",
    "    num_epoch=num_epoch, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    device=device, \n",
    "    max_iter=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.73      0.82      0.77      1000\n",
      "  automobile       0.83      0.88      0.86      1000\n",
      "        bird       0.75      0.65      0.69      1000\n",
      "         cat       0.63      0.65      0.64      1000\n",
      "        deer       0.72      0.72      0.72      1000\n",
      "         dog       0.72      0.75      0.73      1000\n",
      "        frog       0.81      0.76      0.79      1000\n",
      "       horse       0.71      0.83      0.77      1000\n",
      "        ship       0.84      0.77      0.81      1000\n",
      "       truck       0.91      0.78      0.84      1000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As the same type of analysis of predictations\n",
    "predictations, true_labels = predict(model=best_model, data_loader=testloader, device=device)\n",
    "print(classification_report(true_labels, predictations, target_names=cifar10_classes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Relax 'freezing' contstrains and let's train the whole network\n",
    "for param in model_cifar.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Also decrease the learning rate. Why we are doing this?\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model_cifar.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   6%|██████████▊                                                                                                                                                             | 101/1563 [00:19<04:35,  5.31it/s]\n",
      "evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:19<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], train loss: 0.0488, train acc: 0.0491, val loss: 0.6007, val acc: 0.7954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   6%|██████████▊                                                                                                                                                             | 101/1563 [00:19<04:36,  5.28it/s]\n",
      "evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:19<00:00, 16.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], train loss: 0.0323, train acc: 0.0546, val loss: 0.4479, val acc: 0.8480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   6%|██████████▊                                                                                                                                                             | 101/1563 [00:19<04:38,  5.26it/s]\n",
      "evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:19<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], train loss: 0.0284, train acc: 0.0555, val loss: 0.3915, val acc: 0.8634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   6%|██████████▊                                                                                                                                                             | 101/1563 [00:19<04:36,  5.28it/s]\n",
      "evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:19<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], train loss: 0.0261, train acc: 0.0569, val loss: 0.3608, val acc: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   6%|██████████▊                                                                                                                                                             | 101/1563 [00:19<04:35,  5.31it/s]\n",
      "evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:19<00:00, 16.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], train loss: 0.0211, train acc: 0.0583, val loss: 0.3363, val acc: 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Finally do the same training we did before\n",
    "best_model = train_and_validate(\n",
    "    model=model_cifar, \n",
    "    train_loader=trainloader, \n",
    "    val_loader=testloader, \n",
    "    num_epoch=num_epoch, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    device=device, \n",
    "    max_iter=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.90      0.88      0.89      1000\n",
      "  automobile       0.95      0.94      0.95      1000\n",
      "        bird       0.88      0.84      0.86      1000\n",
      "         cat       0.83      0.72      0.77      1000\n",
      "        deer       0.85      0.90      0.87      1000\n",
      "         dog       0.79      0.88      0.83      1000\n",
      "        frog       0.91      0.93      0.92      1000\n",
      "       horse       0.90      0.91      0.90      1000\n",
      "        ship       0.93      0.93      0.93      1000\n",
      "       truck       0.94      0.93      0.93      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As the same type of analysis of predictations\n",
    "predictations, true_labels = predict(model=best_model, data_loader=testloader, device=device)\n",
    "print(classification_report(true_labels, predictations, target_names=cifar10_classes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\">[TODO]</font></b>: Conduct fine-tuning experiments for DTD dataset. What is the accuracy, how does it compare to the 'from-scratch' experiments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO-O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\">[TODO]</font></b>: Conduct fine-tuning experiments for COCO-O dataset. What is the accuracy, how does it compare to the 'from-scratch' experiments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the results with FiftyOne lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\">[TODO]</font></b>: Using the example from the previous 'Practice (Lecture 1)' session and the guidance from the provided [LINK](https://docs.voxel51.com/recipes/adding_classifications.html), analyze the COCO-O results using the FiftyOne tool. Specifically, focus on examining instances where the predictions do not align with the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Q2C1j43ia-PP",
    "j_no4Mw2a-Pc"
   ],
   "name": "ucu_cv2024_module2_practice01.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "cv2024",
   "language": "python",
   "name": "cv2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
