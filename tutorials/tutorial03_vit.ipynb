{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U9M6mtQU1LE3"
   },
   "source": [
    "Tutorial 3 (ViT)\n",
    "======================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the assignment, you will gain some experience working with Visual Transformers (ViT).\n",
    "The main activties will be around fine-tuning ViT model using HuggingFace Lib.\n",
    "\n",
    "* **Fine-tuning ViT model**:\n",
    "\n",
    "    Fine-tune the ViT model on the CIFAR-10, DTD, and COCO-O datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "* The <b><font color=\"red\">red</font></b> color indicates the task that should be done, like <b><font color=\"red\">[TODO]</font></b>: ...\n",
    "* Addicitional comments, hints are in <b><font color=\"blue\">blue</font></b>. For example <b><font color=\"blue\">[HINT]</font></b>: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelimiaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install fiftyone\n",
    "# !pip install scikit-learn\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots a bit nicer\n",
    "plt.matplotlib.rcParams.update({'font.size': 18, 'font.family': 'serif'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hf_cocoo_dataset(path_coco_o:str , path_data:str, seed:int =42, test_ratio=0.3):\n",
    "    def load_image(example):\n",
    "        example['image'] = Image.open(example['image_path'])\n",
    "        return example\n",
    "\n",
    "    if not os.path.exists(path_coco_o):\n",
    "        url = 'https://drive.google.com/uc?id=1aBfIJN0zo_i80Hv4p7Ch7M8pRzO37qbq'\n",
    "        zip_file_path = os.path.join(path_data, 'ood_coco.zip')\n",
    "        gdown.download(url, zip_file_path, quiet=False)\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(path_data)\n",
    "\n",
    "    cocoo_classes_list = os.listdir(path_coco_o)\n",
    "    all_elements_coco = [\n",
    "        (os.path.join(path_coco_o, label, 'val2017', img), index) \n",
    "        for index, label in enumerate(cocoo_classes_list) \n",
    "        for img in os.listdir(os.path.join(path_coco_o, label, 'val2017'))\n",
    "    ]\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    indices = np.arange(len(all_elements_coco))\n",
    "    np.random.shuffle(indices)\n",
    "    n_test = int(len(indices) * test_ratio)\n",
    "\n",
    "    train_indices, test_indices = indices[n_test:], indices[:n_test]\n",
    "    datasets = {}\n",
    "\n",
    "    for split, split_indices in zip(['train', 'test'], [train_indices, test_indices]):\n",
    "        split_data = [(all_elements_coco[i][0], all_elements_coco[i][1]) for i in split_indices]\n",
    "        image_paths, labels = zip(*split_data)\n",
    "        dataset = Dataset.from_dict({'image_path': image_paths, 'label': labels})\n",
    "        datasets[split] = dataset.map(load_image, remove_columns=['image_path'])\n",
    "\n",
    "    return DatasetDict(datasets), cocoo_classes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return dict(accuracy=accuracy_score(predictions, labels))\n",
    "\n",
    "def processor_transform(processor):\n",
    "    def curry(example_batch):\n",
    "        inputs = processor([x for x in example_batch['img']], return_tensors='pt')\n",
    "        inputs['labels'] = example_batch['label']\n",
    "        return inputs\n",
    "    return curry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the local folder with the data\n",
    "path_data = \"./data\"\n",
    "os.makedirs(path_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cifar10 dataset\n",
    "cifar10_dataset = load_dataset('cifar10', cache_dir=path_data)\n",
    "cifar10_classes_list = cifar10_dataset['train'].features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DTD dataset\n",
    "dtd_dataset = load_dataset(\"tanganke/dtd\", cache_dir=path_data)\n",
    "dtd_classes_list = dtd_dataset['train'].features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO-O dataset\n",
    "path_coco_o = os.path.join(path_data, 'ood_coco')\n",
    "cocoo_dataset, cocoo_classes_list = create_hf_cocoo_dataset(path_coco_o, path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the 'base' version of the ViT family\n",
    "model_name = \"google/vit-base-patch16-224\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special object for preprocessing\n",
    "processor = ViTImageProcessor.from_pretrained(model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the transform to match what the processor expects\n",
    "transform_vit = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrain model\n",
    "model = ViTForImageClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect model\n",
    "#print(model)\n",
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correct number of classes\n",
    "# Note: ignore warning\n",
    "num_classes = len(cifar10_classes_list)\n",
    "model = ViTForImageClassification.from_pretrained(model_name, num_labels=num_classes, ignore_mismatched_sizes=True)\n",
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    logging_dir='./logs',    \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will take a small subset of the dataset to speed up things\n",
    "# We are free to play with different number of (n_train, n_test)\n",
    "n_train = 2000\n",
    "n_test = 1000\n",
    "train_subset = cifar10_dataset['train'].select(range(n_train))\n",
    "test_subset = cifar10_dataset['test'].select(range(n_test))\n",
    "\n",
    "# Prepare data for Trainer\n",
    "transform_func = processor_transform(processor)\n",
    "ds_train = train_subset.with_transform(transform_func)\n",
    "ds_test = test_subset.with_transform(transform_func)\n",
    "\n",
    "ds_test_full = cifar10_dataset['test'].with_transform(transform_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HuggingFace 'Trainer'\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args, \n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_test,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "outputs = trainer.predict(ds_test_full)\n",
    "print(outputs.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictations = outputs.predictions.argmax(1)\n",
    "true_labels = cifar10_dataset['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis (report)\n",
    "print(classification_report(true_labels, predictations, target_names=cifar10_classes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis (confusion matrix)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictations)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cifar10_classes_list)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp.plot(cmap='Blues', ax=ax, xticks_rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cocoo_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\">[TODO]</font></b>: Conduct fine-tuning experiments for DTD dataset or COCO-O dataset or both. What is the accuracy, how does it compare to the cnn-based experiments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the results with FiftyOne lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\">[TODO]</font></b>: Using the example from the previous 'Practice (Lecture 1)' session and the guidance from the provided [LINK](https://docs.voxel51.com/recipes/adding_classifications.html), analyze the COCO-O results using the FiftyOne tool. Specifically, focus on examining instances where the predictions do not align with the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Q2C1j43ia-PP",
    "j_no4Mw2a-Pc"
   ],
   "name": "ucu_cv2024_module2_practice01.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "cv2024",
   "language": "python",
   "name": "cv2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
